{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "biLSTM Sarcasm_Classification_Presentation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "v1o75snDKwMZ",
        "QeSsoln-LCQX",
        "yTyjFotENR8b",
        "2V_U_zrxdMnY",
        "uGiHqw8kdEPm",
        "9UMIYJ0_fw-D",
        "z0g1sSfdfroo"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM24VERaJjCiuyRYPUw6yy1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f884282bed2a4519a9e91867543c660b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_364d05e95e154337b11aba70992add81",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_98546bb0163a429a8563f028427e5b2a",
              "IPY_MODEL_cfa99dd5461e43f3b5146fc6782a039d"
            ]
          }
        },
        "364d05e95e154337b11aba70992add81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98546bb0163a429a8563f028427e5b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4e10e6c8cff74f47971b71845d513911",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ceac63437a542668ff847bcb92306e2"
          }
        },
        "cfa99dd5461e43f3b5146fc6782a039d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bb484dd6756a4138b525c282d78a75ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.50MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6f71ca5138143eabe3fbe3d71ecced6"
          }
        },
        "4e10e6c8cff74f47971b71845d513911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ceac63437a542668ff847bcb92306e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb484dd6756a4138b525c282d78a75ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6f71ca5138143eabe3fbe3d71ecced6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danafaiez/Sarcasm_detection/blob/main/Bi/LSTM_Sarcasm_Classification_NwesDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQHzgzOeEX9P",
        "outputId": "a5c9d478-3463-4ec5-a781-d3ae9f96d788"
      },
      "source": [
        "from scipy import spatial\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import drive\n",
        "\n",
        "auth.authenticate_user()\n",
        "project_ID ='exalted-amphora-266020'\n",
        "!gcloud config set project {project_ID}\n",
        "!gsutil ls\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "gs://test_model_dana/\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVpthoxxHDCg"
      },
      "source": [
        "### Sarcasm Detection\n",
        "\n",
        "### Goal: \n",
        "\n",
        "*   Detect sarcasm in text.\n",
        "\n",
        "\n",
        "### Dataset:\n",
        "\n",
        "*   [News Headlines Dataset For Sarcasm Detection](https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection), collected from two news website:  *TheOnion* which produces sarcastic* versions of current events and *HuffPost*. \n",
        "\n",
        "#### Motivation:\n",
        "  1.   Sarcasm Detection is important for an effectice and accurate sentiment analysis and underatanding of the intention. \n",
        "\n",
        "  2.   Sarcasm Detection is especially challenging when working with text data, due to the lack of tone and facial expressions as well as the inherent dependence of sarcasm on the context.\n",
        "\n",
        "  3. Many previous studies used Twitter dataset for sarcasm detection which have the following disadvantages compared to the News Headlines dataset:\n",
        "\n",
        "    *   More likely to have spelling mistakes. This reduces the chance of finding pre-trained (meaningful) embeddings for the words.\n",
        "    *   The Twitter dataset relies on 'sarcasm' hashtangs added by the author. This can add noise to the dataset (labels).\n",
        "\n",
        "### Procedure:\n",
        "\n",
        "  1.   Load, clean, and balance the News Headline Dataset\n",
        "  2.   Prepare data for BERT; get embeddings for the headlines. \n",
        "  3.   Prepare data for LSTM.\n",
        "  4.   Build model.\n",
        "  5.   Train, hyperparameter tune, and evaluate.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw-EaYENGZuC"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install torchvision \n",
        "!pip install talos\n",
        "!pip install h5py\n",
        "!pip install wordcloud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJqli4hxBFP9"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWEH-ueOF_gF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c9e6359-5e6c-4f99-99c5-627753a29a24"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as np\n",
        "import string \n",
        "import re \n",
        "import time\n",
        "\n",
        "import torch\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, Bidirectional, Flatten, Embedding, Concatenate\n",
        "from keras import Input\n",
        "\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import TensorBoard\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud, ImageColorGenerator\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMBSTjJaISw8"
      },
      "source": [
        "### Loading and cleaning Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3ZxYGn5akk2E",
        "outputId": "c0145fbf-a5ce-4dec-c55b-584830f41cb7"
      },
      "source": [
        "tf.version.VERSION"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3363Y3KrZpX"
      },
      "source": [
        "def load_data(n):\n",
        "  def clean_text(headline):\n",
        "            #return headline.translate(str.maketrans(dict.fromkeys(string.punctuation))) \n",
        "            #headline = re.sub(r\"[,.;@_#?!\\\"&$:]+\", ' ', headline) \n",
        "            #headline = re.sub(r\"\\s+\", ' ', headline)\n",
        "            return headline\n",
        "\n",
        "  srcsm_json = requests.get('https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json')\n",
        "  sentences_clean = []\n",
        "  labels = []\n",
        "  i=0\n",
        "  for item in srcsm_json.json():\n",
        "      if i<n:\n",
        "        sentences_clean.append(clean_text(item['headline']))\n",
        "        labels.append(item['is_sarcastic'])\n",
        "        i+=1\n",
        "\n",
        "  df = pd.DataFrame({'text' : sentences_clean[:], 'label':labels[:]})\n",
        "  # label 0: not-sarcastic; label 1: sarcastic\n",
        "  return df"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn8tLc9qH4SG"
      },
      "source": [
        "####  News Dataset  ####\n",
        "\n",
        "def balanced_data(df):\n",
        "  # Make data balanced:\n",
        "\n",
        "  ## Get the number of sarcastic vs non-sarcastic rows  \n",
        "  def get_diff_classes(df):  \n",
        "    count_list = list(df['label'].value_counts())\n",
        "    return count_list[0]-count_list[1]\n",
        "\n",
        "  diff = get_diff_classes(df)\n",
        "\n",
        "\n",
        "  def plot_data_count(df, title):        \n",
        "    f, ax = plt.subplots(1)\n",
        "    sns.set_style('whitegrid')\n",
        "    sns.countplot(x='label',data=df, palette='YlGnBu_r', ax=ax)\n",
        "    ax.set_xticklabels([\"Non-sarcastic\",\"Sarcastic\"])\n",
        "    ax.set(title = title, xlabel='Label', ylabel='Counts')\n",
        "\n",
        "  if diff !=0:\n",
        "    plot_data_count(df, 'Counts of non/sarcastic data before balancing')\n",
        "    print('Before balancing the data, (non-sarcasic - sarcasic) sentences :', get_diff_classes(df))\n",
        "    if diff>0: datatype = 0 # remove from non-sarcasic class\n",
        "    else: datatype = 1 # remove from sarcasic class\n",
        "    np.random.seed(0)\n",
        "    drop_indices = np.random.choice(df[df['label'] == datatype].index, abs(diff), replace=False)\n",
        "    df = df.drop(drop_indices)\n",
        "    print('After balancing the data, (non-sarcasic - sarcasic) sentences :', get_diff_classes(df))\n",
        "    plot_data_count(df, 'Counts of non/sarcastic data after balancing')\n",
        "\n",
        "  print(\"df.info():\\n\",df.info())\n",
        "  print(\"There are\", len(df), \"total sentences.\\n\") \n",
        "  return df\n",
        "  "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ry0NOz9I7pt"
      },
      "source": [
        "####  Shuffling Dataset  ####\n",
        "def shuffle_data(df):\n",
        "  df = df.reindex(np.random.permutation(df.index))\n",
        "  print(\"Top 10 sentences and labels:\\n\", df.head(10))\n",
        "  return df"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB3qgVkpJENn"
      },
      "source": [
        "def get_sentences_labels(df):\n",
        "  sentences = df['text'].tolist()\n",
        "  labels = df['label'].tolist()\n",
        "  return sentences, labels"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF9yNptnKBhO"
      },
      "source": [
        "### Preparing data for BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9nSGL_wE5Q8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "f884282bed2a4519a9e91867543c660b",
            "364d05e95e154337b11aba70992add81",
            "98546bb0163a429a8563f028427e5b2a",
            "cfa99dd5461e43f3b5146fc6782a039d",
            "4e10e6c8cff74f47971b71845d513911",
            "4ceac63437a542668ff847bcb92306e2",
            "bb484dd6756a4138b525c282d78a75ab",
            "f6f71ca5138143eabe3fbe3d71ecced6"
          ]
        },
        "outputId": "7c68cecd-db81-4b4a-ed0a-173865dc9cf6"
      },
      "source": [
        "# bert-base-uncased : 12-layer, 768-hidden, 12-heads, 110M parameters. Trained on lower-cased English text.\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f884282bed2a4519a9e91867543c660b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhIttG88pk1t"
      },
      "source": [
        "##### A quick example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iX2NbF5KA2u",
        "outputId": "4d4f4267-2996-4c25-8a19-e3d673a1493f"
      },
      "source": [
        "text = \"Here is the sentence I want embeddings for.\"\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "# Tokenize our sentence with the BERT tokenizer.\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "# Print out the tokens.\n",
        "print(tokenized_text)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uox65MVKKCu"
      },
      "source": [
        "def tokenizer_inptID(sentences):\n",
        "  \n",
        "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "  input_ids = []\n",
        "\n",
        "  for sent in sentences:\n",
        "      # `encode` will:\n",
        "      #   (1) Tokenize the sentence.\n",
        "      #   (2) Prepend the `[CLS]` token to the start (with ID 101).\n",
        "      #   (3) Append the `[SEP]` token to the end (with ID 102).\n",
        "      #   (4) Map tokens to their IDs.\n",
        "      encoded_sent = tokenizer.encode(\n",
        "                          sent,                      \n",
        "                          add_special_tokens = True, \n",
        "                    )\n",
        "      \n",
        "      \n",
        "      input_ids.append(encoded_sent)\n",
        "\n",
        "\n",
        "  return input_ids"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gET3TWZCKPJL"
      },
      "source": [
        "# Get the length of the longest encoded sentence \n",
        "def get_max_len(input_ids):\n",
        "  MAX_LEN = max([len(sen) for sen in input_ids])\n",
        "  return MAX_LEN"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp_TU6DIKd8-"
      },
      "source": [
        "def padding(input_ids, MAX_LEN):\n",
        "\n",
        "  # Pad our input tokens with value 0.\n",
        "  # \"post\" indicates that we want to pad and truncate at the end of the sequence, as opposed to the beginning.\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                            value=0, truncating=\"post\", padding=\"post\")\n",
        "  \n",
        "  \n",
        "  return input_ids"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDQmlcUfKgVB"
      },
      "source": [
        "def Create_segmentsids_attentionmasks(input_ids):\n",
        "  attention_masks = []\n",
        "  segments_ids = []\n",
        "  # For each sentence...\n",
        "  for id_sent in input_ids:\n",
        "      \n",
        "      # Create the attention mask:\n",
        "      ##  If a token ID is 0, then it's padding, then set the mask to 0 otherwise it's a real token, set the mask to 1.\n",
        "      att_mask = [int(token_id > 0) for token_id in id_sent]\n",
        "      # Create the segmentation embeddings:\n",
        "      segm_id = [0 for token_id in id_sent]\n",
        "      \n",
        "      attention_masks.append(att_mask)\n",
        "      segments_ids.append(segm_id)\n",
        "  \n",
        "  \n",
        "  return attention_masks, segments_ids"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNJGLQJNKiTa"
      },
      "source": [
        "def get_embedding(input_ids, segments_ids, attention_masks):\n",
        "  # Convert the list of IDs to a tensor of IDs \n",
        "  #[torch.LongTensor] is an int64 data type value.\n",
        "  #[torch.Tensor] is a float32 data type value.\n",
        "  model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=False)\n",
        "  input_ids_tensor = torch.tensor(input_ids)\n",
        "  segments_tensors = torch.tensor(segments_ids) \n",
        "  attention_tensors = torch.tensor(attention_masks)\n",
        "\n",
        "\n",
        "  # Set the device to GPU (cuda) if available, otherwise stick with CPU\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  model = model.to(device)\n",
        "  input_ids = input_ids_tensor.to(device)\n",
        "  segments_tensors = segments_tensors.to(device)\n",
        "  attention_tensors = attention_tensors.to(device)\n",
        "  # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "  model.eval()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "      outputs = model(input_ids, token_type_ids=segments_tensors, attention_mask=attention_tensors)\n",
        "      # Transformers models always output tuples.\n",
        "      # The first element is the hidden state of the last layer of the Bert model\n",
        "      encoded_layers = outputs[0]\n",
        "      \n",
        "  \n",
        "\n",
        "  \n",
        "  return encoded_layers"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1o75snDKwMZ"
      },
      "source": [
        "### Preparing embeddings and labels for training/validation process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTAes_MvKsnH"
      },
      "source": [
        "def split(embedding, labels):\n",
        "  rand_state = 0\n",
        "\n",
        "  x_train, x_test, y_train, y_test = train_test_split(embedding, labels, test_size=0.1, random_state=rand_state, stratify=labels)\n",
        "  x_test, x_val, y_test, y_val     = train_test_split(x_test, y_test, test_size=0.5, random_state=rand_state, stratify=y_test)\n",
        "\n",
        "  return x_train, y_train, x_val, y_val, x_test, y_test"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeSsoln-LCQX"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRf5BUS9K9n6"
      },
      "source": [
        "def confusion(preds, labels):\n",
        "  tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
        "  return tn, fp, fn, tp\n",
        "\n",
        "def get_precision(preds, labels):\n",
        "  tn, fp, fn, tp = confusion(preds, labels) \n",
        "  return tp / (tp + fp)\n",
        "\n",
        "def get_recall(preds, labels):\n",
        "  tn, fp, fn, tp = confusion(preds, labels) \n",
        "  return tp / (tp + fn)\n",
        "\n",
        "def get_F1(preds, labels):\n",
        "  precision = get_precision(preds, labels)\n",
        "  recall = get_recall(preds, labels)\n",
        "  F1= 2*(precision*recall)/(precision+recall)\n",
        "  return F1\n",
        "\n",
        "def get_accuracy(preds, labels):\n",
        "  tn, fp, fn, tp = confusion(preds, labels) \n",
        "  accuracy = (tn+tp)/(fp+fn+tn+tp)\n",
        "  return accuracy"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTyjFotENR8b"
      },
      "source": [
        "### Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeKB0HCCwdeB"
      },
      "source": [
        "class Attention(tf.keras.Model):\n",
        "    def __init__(self, units):\n",
        "        super(Attention, self).__init__()\n",
        "        print(\"type(units):\",type(units))\n",
        "        print(\"units:\",units)\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        #print(\"W1.shape:\",self.W1.shape)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        #print(\"W2.shape:\",self.W2.shape)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "        #print(\"V.shape:\",self.V.shape)\n",
        "\n",
        "    def call(self, features, hidden):\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
        "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
        "        context_vector = attention_weights * features\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5KrblzhLGXQ"
      },
      "source": [
        "def build_model(MAX_LEN, batch_size, epochs, metric, hparams, arch_name):\n",
        "\n",
        "  if arch_name == 'lstm':\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(hparams[HP_NUM_UNITS], input_shape=(MAX_LEN,768),return_sequences = False, activation='tanh',recurrent_dropout = hparams[HP_DROPOUT_lstm]))\n",
        "    #model.add(LSTM(hparams[HP_NUM_UNITS], return_sequences = False, activation='tanh',recurrent_dropout = hparams[HP_DROPOUT_lstm])) \n",
        "    model.add(Dropout(hparams[HP_DROPOUT]))\n",
        "    #model.add(Dense(hparams[HP_NUM_UNITS], activation='tanh'))\n",
        "    #model.add(Dropout(hparams[HP_DROPOUT]))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    print(\"weights:\\n\")\n",
        "    model.layers[0].get_weights()[0]\n",
        "    \n",
        "    \n",
        "    \n",
        "  elif arch_name == 'bilstm':\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(hparams[HP_NUM_UNITS], return_sequences=False, activation='tanh', recurrent_dropout = hparams[HP_DROPOUT_lstm]), input_shape=(MAX_LEN,768)))\n",
        "    #model.add(Bidirectional(LSTM(hparams[HP_NUM_UNITS],return_sequences = False, activation='tanh', recurrent_dropout=0.15)))\n",
        "    model.add(Dropout(hparams[HP_DROPOUT]))\n",
        "    #model.add(Dense(50, activation='tanh'))\n",
        "    #model.add(Dropout(hparams[HP_DROPOUT]))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "  \n",
        "  elif arch_name == 'attention':\n",
        "    # Bi-directional attention + Attention\n",
        "    sequence_input = Input(shape=(MAX_LEN,768), batch_size=batch_size)\n",
        "    #print(\"sequence_input.shape:\",sequence_input.shape)\n",
        "    lstm = Bidirectional(LSTM(hparams[HP_NUM_UNITS], return_sequences=True, return_state=True, recurrent_activation='tanh', recurrent_dropout = hparams[HP_DROPOUT_lstm]))(sequence_input)\n",
        "    lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(hparams[HP_NUM_UNITS], return_sequences = True, return_state=True, activation='tanh',recurrent_dropout = hparams[HP_DROPOUT_lstm]))(lstm)\n",
        "    #print(\"(lstm, forward_h.shape, forward_c.shape):\",lstm, forward_h.shape, forward_c.shape)\n",
        "\n",
        "    state_h = Concatenate()([forward_h, backward_h])\n",
        "    state_c = Concatenate()([forward_c, backward_c])\n",
        "    #print(\"after concatenation:\\n\")\n",
        "    #print(\"state_h.shape, state_c.shape:\",state_h.shape, state_c.shape)\n",
        "    context_vector, attention_weights = Attention(hparams[HP_NUM_UNITS])(lstm, state_h)\n",
        "\n",
        "    #print(\"context_vector.shape, attention_weights.shape:\", context_vector.shape, attention_weights.shape)\n",
        "    #dense1 = Dense(50, activation='tanh')(context_vector)\n",
        "    dropout = Dropout(hparams[HP_DROPOUT])(context_vector) #(dense1)\n",
        "    output = Dense(1, activation=\"sigmoid\")(dropout)#(context_vector) \n",
        "    model = keras.Model(inputs = sequence_input, outputs = output) \n",
        "  \n",
        "  else: raise ValueError(\"unexpected architecture name: %r\" % (arch_name,))\n",
        "  \n",
        "  loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "  optimizer_name = hparams[HP_OPTIMIZER]\n",
        "  learning_rate = hparams[HP_L_RATE]\n",
        "\n",
        "\n",
        "  if optimizer_name == \"adam\":\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
        "  elif optimizer_name == \"AdaDelta\":\n",
        "      optimizer = tf.keras.optimizers.Adadelta(learning_rate = learning_rate, rho=0.9, epsilon=1e-06, name=\"Adadelta\", clipnorm = 1.0) # clipnorm used?\n",
        "  else:\n",
        "      raise ValueError(\"unexpected optimizer name: %r\" % (optimizer_name,))\n",
        "\n",
        "  \n",
        "  model.compile(loss = loss, optimizer = optimizer, metrics = metric)\n",
        "  model.summary()\n",
        "\n",
        " \n",
        "  \n",
        "  return model\n",
        "  "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-u6ZLHqPhnj"
      },
      "source": [
        "def fit_model(model, x_train, y_train, x_val, y_val, batch_size, epochs, path, logdir, hparams):\n",
        "              \n",
        "  \n",
        "  callbacks = [EarlyStopping(monitor = 'val_accuracy', mode='max', verbose=1, patience=2), \n",
        "               ModelCheckpoint(path, monitor = 'val_accuracy', mode='max', verbose=1, save_best_only=True),\n",
        "               TensorBoard(log_dir=logdir, histogram_freq=1),  \n",
        "               hp.KerasCallback(logdir, hparams)  \n",
        "               ]\n",
        "\n",
        "  # The returned \"out_model\" object holds a record of the loss values and metric values during training: \n",
        "  out_model = model.fit(x_train, y_train, validation_data = (x_val, y_val), batch_size = batch_size, \n",
        "                        epochs = epochs, shuffle=True, callbacks=callbacks, verbose=1)\n",
        "  \n",
        "  return out_model\n",
        "  "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hN3HjCcPlwS"
      },
      "source": [
        "def evaluate(model, x_test, y_test, batch_sizem):\n",
        "  \n",
        "  print(\"evaluate on test dataset:\\n\")\n",
        "  print(\"model.evaluate(x_test, y_test, batch_size , verbose=1):\",model.evaluate(x_test, y_test, batch_size , verbose=1)) ## check if needed\n",
        "  loss_test, acc_test, auc_test =  model.evaluate(x_test, y_test, batch_size, verbose=1)\n",
        "  \n",
        "  return loss_test, acc_test, auc_test"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LFuLC8oPvCe"
      },
      "source": [
        "##  Begin Loading data and training  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq0xwMkbPm1B",
        "outputId": "43c7d4d3-87a3-4011-dac1-9b684770f625"
      },
      "source": [
        "\n",
        "# Getting and cleaning the data \n",
        "start_time = time.time()\n",
        "n =  22692  \n",
        "\n",
        "df = load_data(n)\n",
        "\n",
        "df = balanced_data(df)\n",
        "\n",
        "df = shuffle_data(df)\n",
        "\n",
        "sentences, labels = get_sentences_labels(df)\n",
        "\n",
        "print(\"total number of sentences:\", len(sentences))\n",
        "# Tokenizing \n",
        "input_ids = tokenizer_inptID(sentences)\n",
        "MAX_LEN = get_max_len(input_ids)\n",
        "print(\"MAX_LEN:\",MAX_LEN)\n",
        "\n",
        "\n",
        "# Input ID, Segment ID, and attention mask\n",
        "partition_size = 5000  #250\n",
        "input_ids_pad = []; start = 0\n",
        "for i in range(1, 5):\n",
        "  m = partition_size*i\n",
        "  input_ids_pad.extend(list(padding(input_ids[start:m], MAX_LEN)))\n",
        "  start = m\n",
        "input_ids = np.array(input_ids_pad)\n",
        "\n",
        "attention_masks, segments_ids = Create_segmentsids_attentionmasks(input_ids)\n",
        "\n",
        "# Get the embeddings\n",
        "partition_size = 5000 #250\n",
        "res = [] ; start = 0\n",
        "input_ids_list = list(input_ids)\n",
        "\n",
        "for i in range(1,5):\n",
        "  m = partition_size*i\n",
        "  print(\"start\")\n",
        "  temp = get_embedding(input_ids_list[start:m], segments_ids[start:m], attention_masks[start:m])\n",
        "  print(\"Done i:\", i)\n",
        "  res.append(temp)\n",
        "  start = m\n",
        "\n",
        "encoded_layers =  torch.cat(res,dim=0)\n",
        "labels = np.array(labels)\n",
        "\n",
        "\n",
        "#normalizing data\n",
        "def normalize(norm_option, embedding):\n",
        "  input = []\n",
        "  if norm_option == 'min_max_scaler': #[0,1]\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    embedding = np.array([min_max_scaler.fit_transform(sent) for sent in embedding])\n",
        "\n",
        "  elif norm_option == 'max_abs_scaler': #[-1,1]  #\n",
        "    max_abs_scaler = preprocessing.MaxAbsScaler()\n",
        "    embedding = np.array([max_abs_scaler.fit_transform(sent) for sent in embedding])\n",
        "\n",
        "  elif norm_option == 'Unit_norm':\n",
        "    embedding = np.array([preprocessing.normalize(sent, norm='l2') for sent in embedding])\n",
        "  return embedding \n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "# metric\n",
        "metric = [keras.metrics.BinaryAccuracy(name='accuracy'), keras.metrics.AUC(name='auc')]\n",
        "\n",
        "####### Hyper param tuning #######\n",
        "\n",
        "#Clear any logs from previous runs\n",
        "!rm -rf ./logs/* \n",
        "\n",
        "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([40])) \n",
        "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.70]))\n",
        "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['AdaDelta']))\n",
        "HP_L_RATE = hp.HParam('learning_rate', hp.Discrete([1.0]))\n",
        "HP_DROPOUT_lstm = hp.HParam('dropout_lsm', hp.Discrete([0.15]))\n",
        "\n",
        "hp_dict = {'hidden_units' : HP_NUM_UNITS, 'dropout': HP_DROPOUT, 'optimizer': HP_OPTIMIZER, 'lr':HP_L_RATE,'dropout_lstm': HP_DROPOUT_lstm}\n",
        "\n",
        "batch_size = 32 #20 \n",
        "epochs = 10\n",
        "\n",
        "\n",
        "def run(logdir, hparams, xtrain, ytrain, xval, yval, xtest, ytest, path_session, best_weights, eval, arch_name):\n",
        "  with tf.summary.create_file_writer(logdir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    model = build_model(MAX_LEN, batch_size, epochs, metric, hparams, arch_name) \n",
        "    dot_img_file = '/content/model_1.png'\n",
        "    tf.keras.utils.plot_model(model, to_file = dot_img_file, show_shapes=True)\n",
        "\n",
        "    if eval==False:\n",
        "      out_model = fit_model(model, xtrain, ytrain, xval, yval, batch_size, epochs, path_session, logdir, hparams)\n",
        "      valacc = (out_model.history['val_accuracy'])\n",
        "      valauc = (out_model.history['val_auc'])\n",
        "      print('val_acc:', valacc[-1], 'val_auc:', valauc[-1])\n",
        "      tf.summary.scalar('accuracy', valacc[-1], step = epochs) \n",
        "    \n",
        "    else:  \n",
        "      model.load_weights(best_weights)\n",
        "      loss_test, acc_test, auc_test =  model.evaluate(xtest, ytest, batch_size, verbose=1)\n",
        "      print(\"loss_test:\", loss_test, \"acc_test:\", acc_test, \"auc_test:\", auc_test)\n",
        "\n",
        "      pred = model.predict(xtest)\n",
        "      #print(\"pred:\",pred)\n",
        "      print(\"len of test dataset:\", len(pred))\n",
        "      for thresh in np.linspace(0.3, 0.7, num=5):\n",
        "        pred_temp = [int(prob > thresh) for prob in pred]      \n",
        "        \n",
        "        print(\"#### Threshold: ####\" , thresh)\n",
        "        (tn, fp, fn, tp) = confusion(pred_temp, ytest)\n",
        "        print(\"False predictions of non-sarcasm:\", fn)\n",
        "        print(\"False predictions of sarcasm:\", fp)\n",
        "        print(\"True predictions of non-sarcasm:\", tn)\n",
        "        print(\"True predictions of sarcasm:\", tp)\n",
        "\n",
        "        print(\"Precision:\", get_precision(pred_temp, ytest))\n",
        "        print(\"Recall:\", get_recall(pred_temp, ytest))\n",
        "        print(\"F1:\", get_F1(pred_temp, ytest))\n",
        "        print(\"Accuracy:\", get_accuracy(pred_temp, ytest))\n",
        "        print('\\n')\n",
        "    return model \n",
        "      \n",
        "    \n",
        "\n",
        "def run_tensorboard(hp_dict, best_weights, eval, arch_name, norm, norm_options):\n",
        "  session_num = 0\n",
        "  for num_units in hp_dict['hidden_units'].domain.values:\n",
        "    for dropout_rate in hp_dict['dropout'].domain.values: \n",
        "        for opt in hp_dict['optimizer'].domain.values:\n",
        "          for learning_rate in hp_dict['lr'].domain.values:\n",
        "            for dropout_rate_lstm in hp_dict['dropout_lstm'].domain.values:\n",
        "                hparams = {\n",
        "                    HP_NUM_UNITS : num_units,\n",
        "                    HP_DROPOUT : dropout_rate,\n",
        "                    HP_OPTIMIZER : opt,\n",
        "                    HP_L_RATE : learning_rate,\n",
        "                    HP_DROPOUT_lstm : dropout_rate_lstm, \n",
        "\n",
        "                }\n",
        "                # Preperaing the data for training\n",
        "                embedding = encoded_layers.numpy() \n",
        "\n",
        "                if norm == True:\n",
        "                  for norm_option in norm_options:\n",
        "                    print(\"_____norm_option_____:\", norm_option)\n",
        "                    embedding = normalize(norm_options, embedding)\n",
        "                    x_train, y_train, x_val, y_val, x_test, y_test = split(embedding, labels)  \n",
        "                    run_name = \"run-%d\" % session_num\n",
        "                    print('---- Starting trial ----: %s' % run_name)\n",
        "                    print({h.name: hparams[h] for h in hparams})\n",
        "                    path_session = \"file_\" + str(session_num) + \".hdf5\" # Best weights are saved here for each set of hyperparameters\n",
        "                    model = run('logs/hptune_2/' + run_name, hparams, x_train, y_train, x_val, y_val, x_test, y_test, path_session, best_weights, eval, arch_name)\n",
        "                    session_num += 1\n",
        "                    print(\"\\n\")\n",
        "                else:\n",
        "                  print(\"_____norm_option_____:\" + \" not normalizing\")\n",
        "                  x_train, y_train, x_val, y_val, x_test, y_test = split(embedding, labels)  \n",
        "                  run_name = \"run-%d\" % session_num\n",
        "                  print('---- Starting trial ----: %s' % run_name)\n",
        "                  print({h.name: hparams[h] for h in hparams})\n",
        "                  path_session = \"file_\" + str(session_num) + \".hdf5\"\n",
        "                  model = run('logs/hptune_2/' + run_name, hparams, x_train, y_train, x_val, y_val, x_test, y_test, path_session, best_weights, eval, arch_name)\n",
        "                  session_num += 1\n",
        "                  print(\"\\n\")\n",
        "\n",
        "  return model\n",
        "#######  Tune Hyperparameter on Validation Dataset and Save the Best Weights #######\n",
        "#norm_options = ['min_max_scaler', 'max_abs_scaler','Unit_norm']\n",
        "model = run_tensorboard(hp_dict, best_weights=None, eval = False, arch_name = 'bilstm', norm = False, norm_options = ['Unit_norm']) #'attention', 'bilstm', 'lstm'\n",
        "print(\"time to train/evaluate:\\n\")\n",
        "print(\"%s\" % (time.time() - start_time))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_____norm_option_____: not normalizing\n",
            "---- Starting trial ----: run-0\n",
            "{'num_units': 40, 'dropout': 0.7, 'optimizer': 'AdaDelta', 'learning_rate': 1.0, 'dropout_lsm': 0.15}\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_4 (Bidirection (None, 80)                258880    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 81        \n",
            "=================================================================\n",
            "Total params: 258,961\n",
            "Trainable params: 258,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "563/563 [==============================] - 83s 140ms/step - loss: 0.4654 - accuracy: 0.7738 - auc: 0.8531 - val_loss: 0.3467 - val_accuracy: 0.8440 - val_auc: 0.9447\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.84400, saving model to file_0.hdf5\n",
            "Epoch 2/10\n",
            "563/563 [==============================] - 76s 136ms/step - loss: 0.3083 - accuracy: 0.8707 - auc: 0.9416 - val_loss: 0.2835 - val_accuracy: 0.8780 - val_auc: 0.9545\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.84400 to 0.87800, saving model to file_0.hdf5\n",
            "Epoch 3/10\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.2537 - accuracy: 0.8992 - auc: 0.9601 - val_loss: 0.2774 - val_accuracy: 0.8840 - val_auc: 0.9645\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.87800 to 0.88400, saving model to file_0.hdf5\n",
            "Epoch 4/10\n",
            "563/563 [==============================] - 76s 134ms/step - loss: 0.2184 - accuracy: 0.9123 - auc: 0.9705 - val_loss: 0.2845 - val_accuracy: 0.8750 - val_auc: 0.9621\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.88400\n",
            "Epoch 5/10\n",
            "563/563 [==============================] - 77s 137ms/step - loss: 0.1888 - accuracy: 0.9286 - auc: 0.9778 - val_loss: 0.2422 - val_accuracy: 0.8970 - val_auc: 0.9701\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.88400 to 0.89700, saving model to file_0.hdf5\n",
            "Epoch 6/10\n",
            "563/563 [==============================] - 77s 137ms/step - loss: 0.1638 - accuracy: 0.9386 - auc: 0.9832 - val_loss: 0.2441 - val_accuracy: 0.9060 - val_auc: 0.9689\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.89700 to 0.90600, saving model to file_0.hdf5\n",
            "Epoch 7/10\n",
            "563/563 [==============================] - 77s 137ms/step - loss: 0.1373 - accuracy: 0.9507 - auc: 0.9875 - val_loss: 0.2943 - val_accuracy: 0.8920 - val_auc: 0.9656\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.90600\n",
            "Epoch 8/10\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.1078 - accuracy: 0.9610 - auc: 0.9918 - val_loss: 0.2534 - val_accuracy: 0.9020 - val_auc: 0.9683\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.90600\n",
            "Epoch 00008: early stopping\n",
            "val_acc: 0.9020000100135803 val_auc: 0.9683480262756348\n",
            "\n",
            "\n",
            "time to train/evaluate:\n",
            "\n",
            "622.7865762710571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7akRLzc2lRI",
        "outputId": "23ac65fb-4730-41fe-f91b-d389eb55c1d5"
      },
      "source": [
        "input_ids.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 66)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNK3_kL0QSQB"
      },
      "source": [
        "\n",
        "%reload_ext tensorboard\n",
        "%load_ext tensorboard \n",
        "%tensorboard --logdir logs/hptune_2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgdrsuyiV66F"
      },
      "source": [
        "\n",
        "#######  Evaluating on Test Dataset  #######\n",
        "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([40])) \n",
        "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.7])) \n",
        "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['AdaDelta']))\n",
        "HP_L_RATE = hp.HParam('learning_rate', hp.Discrete([1.0]))\n",
        "HP_DROPOUT_lstm = hp.HParam('dropout_lsm', hp.Discrete([0.15]))\n",
        "\n",
        "hp_dict_opt = {'hidden_units' : HP_NUM_UNITS, 'dropout': HP_DROPOUT, 'optimizer': HP_OPTIMIZER, 'lr':HP_L_RATE,'dropout_lstm': HP_DROPOUT_lstm}\n",
        "\n",
        "best_weights = None ## add the file with best weights here\n",
        "best_weights='/content/file_0.hdf5' \n",
        "\n",
        "\n",
        "#model = run_tensorboard(hp_dict_opt, x_train, y_train, x_test, y_test, best_weights, eval = True, arch_name = 'bilstm')\n",
        "model = run_tensorboard(hp_dict, best_weights=best_weights, eval = True, arch_name = 'bilstm', norm = False, norm_options = ['Unit_norm'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V_U_zrxdMnY"
      },
      "source": [
        "### Prediction on a sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S57Q7u9r8GMF"
      },
      "source": [
        "# Prediction\n",
        "def prediction(sentence):\n",
        "  print(\"tokens:\",tokenizer.tokenize(sentence[0]))\n",
        "  input_ids = tokenizer_inptID(sentence)\n",
        "  print(\"input_ids:\",input_ids)\n",
        "  MAX_LEN = 7\n",
        "  input_ids = padding(input_ids, MAX_LEN)\n",
        "  attention_masks, segments_ids = Create_segmentsids_attentionmasks(input_ids)\n",
        "  # Get the embeddings\n",
        "  embedded_sent = get_embedding(input_ids, segments_ids, attention_masks)\n",
        "  \n",
        "\n",
        "  out = embedded_sent.numpy() \n",
        "  pred = model.predict(out)\n",
        "  \n",
        "  print(\"pred:\", pred)\n",
        "  if pred[0][0]*100>=50: return \"It's a sarcasm\"\n",
        "  else: return \"It's not a sarcasm\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "s = [\"This is a test case\"]\n",
        "prediction(s)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERZnwZZSNlvh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGiHqw8kdEPm"
      },
      "source": [
        "### tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xvX83Oi8oph"
      },
      "source": [
        "def get_data_wpunc(n):\n",
        "  srcsm_json = requests.get('https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json')\n",
        "  sentences_clean = []\n",
        "  labels = []\n",
        "  i=0\n",
        "  for item in srcsm_json.json():\n",
        "      #if i<n:\n",
        "        sentences_clean.append(item['headline'])\n",
        "        labels.append(item['is_sarcastic'])\n",
        "        i+=1\n",
        "  df = pd.DataFrame({'text' : sentences_clean[:], 'label':labels[:]})\n",
        "  print(i)\n",
        "  return df\n",
        "\n",
        "def get_sample(m, df):\n",
        "  #sample_df : a sample of df, inclusing m sarcastic and m snon-sarcastic sentences:\n",
        "  sample_df = pd.concat([df[df['label'] == 0].sample(m, random_state=1) , df[df['label'] == 1].sample(m,random_state=1)], axis=0)\n",
        "  print(\"sample_df:\",len(sample_df))\n",
        "  # all the non-sarcastic sentences joined together, similarly for non-sarcastic sentences\n",
        "  sample_sentences = sample_df.groupby(['label'])['text'].apply(' '.join).reset_index() \n",
        "  documentA = (str(sample_sentences.loc[0,['text']]).split(' ',1)[1]).strip()\n",
        "  documentB = (str(sample_sentences.loc[1,['text']]).split(' ',1)[1]).strip()\n",
        "\n",
        "  pd.options.display.max_colwidth = 12441\n",
        "  #print(\"documentA:\\n\", sample_sentences.loc[0,['text']])\n",
        "  #print(\"documentA:\\n\", len(documentA))\n",
        "  return documentA, documentB"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hpJFRCmi0mS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a78f05b2-fd4b-4729-8abc-81095d2bac82"
      },
      "source": [
        "\n",
        "#tf-idf of sample data and punctuation plot\n",
        "from nltk.corpus import stopwords\n",
        "stopwords = stopwords.words('english')\n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "table = str.maketrans(dict.fromkeys(string.punctuation)) \n",
        "stopwords = stopwords.words('english')\n",
        "ps = PorterStemmer() \n",
        "  \n",
        "n = 26709 \n",
        "\n",
        "\n",
        "df = get_data_wpunc(n)\n",
        "df = balanced_data(df)\n",
        "d = df.to_dict(\"list\")\n",
        "labels = d['label']\n",
        "sentences_clean = d['text']\n",
        "m = int(len(df)/2)\n",
        "documentA, documentB = get_sample(m, df)\n",
        "\n",
        "def get_punctuation_dict(sentences_clean,labels):\n",
        "  d_punc = defaultdict(list)\n",
        "  symbols = \"?!:,-\\\"\"\n",
        "  for symbol in symbols:\n",
        "    count_nc=0; count_c=0\n",
        "    for i, sent in enumerate(sentences_clean):\n",
        "      count = sent.count(symbol)\n",
        "      if labels[i]==0:count_nc+=count\n",
        "      else:count_c+=count\n",
        "    d_punc[symbol].append(count_nc)\n",
        "    d_punc[symbol].append(count_c)\n",
        "\n",
        "  print(\"d_punc:\", d_punc)\n",
        "\n",
        "  data = [[list(d_punc.values())[i][0] for i in range(len(symbols))], [list(d_punc.values())[i][1] for i in range(len(symbols))]]\n",
        "  print(\"len(data):\", len(data))\n",
        "\n",
        "  # plot\n",
        "  X = np.arange(6)\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_axes([0,0,1,1])\n",
        "  ax.bar(X + 0.00, data[0], color = 'b', width = 0.25, label='non-Sarcastic')\n",
        "  ax.bar(X + 0.25, data[1], color = 'g', width = 0.25, label='Sarcastic')\n",
        "  labels = [\"?\",\"?\",\"!\",\":\",\",\",\"-\",\"\\\"\"]\n",
        "  ax.xaxis.set_tick_params(labelsize=17)\n",
        "  ax.set_xticklabels(labels)\n",
        "  ax.legend()\n",
        "\n",
        "#plot punctuation plot\n",
        "get_punctuation_dict(sentences_clean,labels)\n",
        "\n",
        "def clean_text(data):\n",
        "    data = data.translate(table)  \n",
        "    data = data.lower()\n",
        "    data = re.sub(r\"[,.;@_#?!\\\"&$:]+\", ' ', data) \n",
        "    data = re.sub(r\"\\s+\", ' ', data)\n",
        "    data_split = [ps.stem(w) for w in data.split(' ') if w not in stopwords]\n",
        "    data = ' '.join(data_split)\n",
        "    return data, data_split\n",
        "\n",
        "documentA, bagOfWordsA = clean_text(documentA) # non-sarcastic\n",
        "documentB, bagOfWordsB = clean_text(documentB) # sarcastic\n",
        "uniqueWords = set(bagOfWordsA).union(set(bagOfWordsB))\n",
        "\n",
        "corpus = [documentA, documentB]\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 1), min_df=1)\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "feature_names = vectorizer.get_feature_names()\n",
        "#print(feature_name)\n",
        "\n",
        "def get_ifidf_for_words(text):\n",
        "    tfidf_matrix= vectorizer.transform([text]).todense()\n",
        "    feature_index = tfidf_matrix[0,:].nonzero()[1]\n",
        "    tfidf_scores = zip([feature_names[i] for i in feature_index], [tfidf_matrix[0, x] for x in feature_index])\n",
        "    return dict(tfidf_scores)\n",
        "\n",
        "feature_dict_nc = get_ifidf_for_words(documentA)\n",
        "feature_dict_nc = {k: v for k, v in sorted(feature_dict_nc.items(), key=lambda item: item[1], reverse=True)}\n",
        "feature_dict_c = get_ifidf_for_words(documentB)\n",
        "feature_dict_c = {k: v for k, v in sorted(feature_dict_c.items(), key=lambda item: item[1], reverse=True)}\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26709\n",
            "Before balancing the data, (non-sarcasic - sarcasic) sentences : 3261\n",
            "After balancing the data, (non-sarcasic - sarcasic) sentences : 0\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 23448 entries, 0 to 26706\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    23448 non-null  object\n",
            " 1   label   23448 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 1.2+ MB\n",
            "df.info():\n",
            " None\n",
            "There are 23448 total sentences.\n",
            "\n",
            "sample_df: 23448\n",
            "d_punc: defaultdict(<class 'list'>, {'?': [585, 91], '!': [135, 31], ':': [1391, 764], ',': [1851, 1424], '-': [1709, 2641], '\"': [84, 15]})\n",
            "len(data): 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWAV3K0_IkZW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWObsoYYEiIk"
      },
      "source": [
        "def word_could(list_words):\n",
        "    word_could_dict=Counter(list_words)\n",
        "    print(\"word_could_dict:\",word_could_dict)\n",
        "    word_could_dict = {k:v for k,v in word_could_dict.items() if v!=0}\n",
        "    word_could_dict.pop('', None)\n",
        "    wordcloud = WordCloud(width = 1000, height = 500).generate_from_frequencies(word_could_dict)\n",
        "    plt.figure(figsize=(15,8))\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UMIYJ0_fw-D"
      },
      "source": [
        "#### Most important words in non-sarcastic text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPJOrcviRkal"
      },
      "source": [
        "word_could(feature_dict_c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0g1sSfdfroo"
      },
      "source": [
        "#### Most important words in sarcastic text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPkHUgEzR4xE"
      },
      "source": [
        "word_could(feature_dict_nc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d99yhrhmR9Lu"
      },
      "source": [
        "c_nc = Counter(bagOfWordsA)\n",
        "c_nc = {k:v for k,v in c_nc.items() if v!=0}\n",
        "c_nc.pop('', None)\n",
        "cA={k: v for k, v in sorted(c_nc.items(), key=lambda item: item[1], reverse=True)}\n",
        "#print(cA)\n",
        "word_could(cA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPWIf4us6Qxt"
      },
      "source": [
        "c_c = Counter(bagOfWordsB)\n",
        "c_c = {k:v for k,v in c_c.items() if v!=0}\n",
        "c_c.pop('', None)\n",
        "cB={k: v for k, v in sorted(c_c.items(), key=lambda item: item[1], reverse=True)}\n",
        "#print(cB)\n",
        "word_could(cB)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}